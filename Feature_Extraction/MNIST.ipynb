{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset=( datasets.MNIST('./data', train=True, download=True,transform=SimCLRDataTransform(\n",
    "                          transforms.Compose([transforms.RandomResizedCrop(size=28,scale=(0.2,0.8)),\n",
    "                                              GaussianBlur(kernel_size=int(0.1 * 28)),\n",
    "                                              transforms.ToTensor(),\n",
    "                                              transforms.Normalize((0.1307,), (0.3081,))]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torchvision.transforms as transforms\n",
    "from gaussian_blur import GaussianBlur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(28, padding=2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])   \n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])   \n",
    "\n",
    "train_dataset1 = MNIST('./data', train=True, download=True,transform=transform_train)\n",
    "test_dataset1 = MNIST('./data', train=False, download=True,transform=transform_test)\n",
    "\n",
    "train_loader1 = DataLoader(train_dataset1, batch_size=512, shuffle=False, num_workers=0)\n",
    "test_loader1 = DataLoader(test_dataset1, batch_size=2000, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "import numpy as np\n",
    "\n",
    "def decode_idx3_ubyte(idx3_ubyte_file):\n",
    "    with open(idx3_ubyte_file, 'rb') as f:\n",
    "        fb_data = f.read()\n",
    "    offset = 0\n",
    "    fmt_header = '>iiii'    # 以大端法读取4个 unsinged int32\n",
    "    magic_number, num_images, num_rows, num_cols = struct.unpack_from(fmt_header, fb_data, offset)\n",
    "    offset += struct.calcsize(fmt_header)\n",
    "    fmt_image = '>' + str(num_rows * num_cols) + 'B'\n",
    "\n",
    "    images = np.empty((num_images, num_rows, num_cols))\n",
    "    for i in range(num_images):\n",
    "        im = struct.unpack_from(fmt_image, fb_data, offset)\n",
    "        images[i] = np.array(im).reshape((num_rows, num_cols))\n",
    "        offset += struct.calcsize(fmt_image)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "def decode_idx1_ubyte(idx1_ubyte_file):\n",
    "    with open(idx1_ubyte_file, 'rb') as f:\n",
    "        fb_data = f.read()\n",
    "    offset = 0\n",
    "    fmt_header = '>ii'  # 以大端法读取两个 unsinged int32\n",
    "    magic_number, label_num = struct.unpack_from(fmt_header, fb_data, offset)\n",
    "    offset += struct.calcsize(fmt_header)\n",
    "    labels = []\n",
    "    fmt_label = '>B'    # 每次读取一个 byte\n",
    "    for i in range(label_num):\n",
    "        labels.append(struct.unpack_from(fmt_label, fb_data, offset)[0])\n",
    "        offset += struct.calcsize(fmt_label)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "def check_folder(folder):\n",
    "    if not os.path.exists(folder):\n",
    "        os.mkdir(folder)\n",
    "        print(folder)\n",
    "    else:\n",
    "        if not os.path.isdir(folder):\n",
    "            os.mkdir(folder)\n",
    "\n",
    "\n",
    "def export_img(exp_dir, img_ubyte, lable_ubyte):\n",
    "    check_folder(exp_dir)\n",
    "    images = decode_idx3_ubyte(img_ubyte)\n",
    "    labels = decode_idx1_ubyte(lable_ubyte)\n",
    "\n",
    "    nums = len(labels)\n",
    "    for i in range(nums):\n",
    "        img_dir = os.path.join(exp_dir, str(labels[i]))\n",
    "        check_folder(img_dir)\n",
    "        img_file = os.path.join(img_dir, str(i)+'.png')\n",
    "        imarr = images[i]\n",
    "        cv2.imwrite(img_file, imarr)\n",
    "\n",
    "\n",
    "def parser_mnist_data(data_dir):\n",
    "    train_dir = os.path.join(data_dir, 'train')\n",
    "    train_img_ubyte = os.path.join(data_dir, 'train-images.idx3-ubyte')\n",
    "    train_label_ubyte = os.path.join(data_dir, 'train-labels.idx1-ubyte')\n",
    "    export_img(train_dir, train_img_ubyte, train_label_ubyte)\n",
    "\n",
    "    test_dir = os.path.join(data_dir, 'test')\n",
    "    test_img_ubyte = os.path.join(data_dir, 't10k-images.idx3-ubyte')\n",
    "    test_label_ubyte = os.path.join(data_dir, 't10k-labels.idx1-ubyte')\n",
    "    export_img(test_dir, test_img_ubyte, test_label_ubyte)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    data_dir = 'C:\\\\Users\\\\yijia\\\\Desktop\\\\mnist_data'\n",
    "    parser_mnist_data(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
