{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fc8b970",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.transforms import Compose, Resize, CenterCrop, ToTensor, Normalize\n",
    "import numpy as np\n",
    "from scipy import io\n",
    "import os\n",
    "import clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccaaca38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RN50',\n",
       " 'RN101',\n",
       " 'RN50x4',\n",
       " 'RN50x16',\n",
       " 'RN50x64',\n",
       " 'ViT-B/32',\n",
       " 'ViT-B/16',\n",
       " 'ViT-L/14',\n",
       " 'ViT-L/14@336px']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "clip.available_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bce196a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, preprocess = clip.load(\"RN50x64\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02cd5f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import clip\n",
    "try:\n",
    "    from torchvision.transforms import InterpolationMode\n",
    "    BICUBIC = InterpolationMode.BICUBIC\n",
    "except ImportError:\n",
    "    BICUBIC = Image.BICUBIC\n",
    "    \n",
    "\n",
    "def _convert_image_to_rgb(image):\n",
    "    return image.convert(\"RGB\")\n",
    "    \n",
    "def _transform(n_px):\n",
    "    return Compose([\n",
    "        Resize(n_px, interpolation=BICUBIC),\n",
    "        CenterCrop(n_px),\n",
    "        _convert_image_to_rgb,\n",
    "        ToTensor(),\n",
    "        Normalize((0.48145466, 0.4578275, 0.40821073), (0.26862954, 0.26130258, 0.27577711)),\n",
    "    ])\n",
    "\n",
    "def features32(self, x):\n",
    "    def stem(x):\n",
    "        x = self.relu1(self.bn1(self.conv1(x)))\n",
    "        x = self.relu2(self.bn2(self.conv2(x)))\n",
    "        x = self.relu3(self.bn3(self.conv3(x)))\n",
    "        x = self.avgpool(x)\n",
    "        return x\n",
    "\n",
    "    x = x.type(self.conv1.weight.dtype)\n",
    "    x = stem(x)\n",
    "    x = self.layer1(x)\n",
    "    x = self.layer2(x)\n",
    "    x = self.layer3(x)\n",
    "    x = self.layer4(x)\n",
    "    x=F.avg_pool2d(x,x.shape[2])\n",
    "\n",
    "    return x\n",
    "\n",
    "# def features32(net, x):\n",
    "#     x = x.type(net.conv1.weight.dtype)\n",
    "#     for conv, bn in [(net.conv1, net.bn1), (net.conv2, net.bn2), (net.conv3, net.bn3)]:\n",
    "#         x = net.relu(bn(conv(x)))\n",
    "#     #print(1,x.shape)\n",
    "#     x = net.avgpool(x)\n",
    "#     x = net.layer1(x)\n",
    "#     x = net.layer2(x)\n",
    "#     x = net.layer3(x)\n",
    "#     x = net.layer4(x)\n",
    "#     #print(2,x.shape)\n",
    "#     #x = net.attnpool(x)\n",
    "#     x=F.avg_pool2d(x,x.shape[2])\n",
    "#     return x\n",
    "\n",
    "def features(net, x):\n",
    "    x = x.type(net.conv1.weight.dtype)\n",
    "    for conv, bn in [(net.conv1, net.bn1), (net.conv2, net.bn2), (net.conv3, net.bn3)]:\n",
    "        x = net.relu(bn(conv(x)))\n",
    "    #print(1,x.shape)\n",
    "    x = net.avgpool(x)\n",
    "    x = net.layer1(x)\n",
    "    x = net.layer2(x)\n",
    "    x = net.layer3(x)\n",
    "    x = net.layer4(x)\n",
    "    #print(2,x.shape)\n",
    "    x = net.attnpool(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdd5e76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "class ImageFolderWithPaths(datasets.ImageFolder):\n",
    "    \"\"\"Custom dataset that includes image file paths. Extends\n",
    "    torchvision.datasets.ImageFolder\n",
    "    \"\"\"\n",
    "    # override the __getitem__ method. this is the method that dataloader calls\n",
    "    def __getitem__(self, index):\n",
    "        # this is what ImageFolder normally returns\n",
    "        original_tuple = super(ImageFolderWithPaths, self).__getitem__(index)\n",
    "        # print('original_tuple = ', original_tuple)\n",
    "        # the image file path\n",
    "        path = self.imgs[index][0]\n",
    "        # print('the image file full path = ', path)\n",
    "        # make a new tuple that includes original and the path\n",
    "        tuple_with_path = (original_tuple + (path,))\n",
    "        return tuple_with_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d35e77e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set =  Dataset ImageFolderWithPaths\n",
      "    Number of datapoints: 50000\n",
      "    Root location: C:\\Users\\Yijia Zhou\\Desktop\\cifar-10-python\\cifar10\\train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               Resize(size=144, interpolation=bicubic, max_size=None, antialias=None)\n",
      "               CenterCrop(size=(144, 144))\n",
      "               <function _convert_image_to_rgb at 0x000002388D612B80>\n",
      "               ToTensor()\n",
      "               Normalize(mean=(0.48145466, 0.4578275, 0.40821073), std=(0.26862954, 0.26130258, 0.27577711))\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "train_path =\"C:\\\\Users\\\\Yijia Zhou\\\\Desktop\\\\cifar-10-python\\\\cifar10\\\\train\"\n",
    "train_set = ImageFolderWithPaths(train_path, transform=_transform(144))\n",
    "print('train_set = ', train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6c768db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x238e41c84c0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "loader = torch.utils.data.DataLoader(train_set)\n",
    "loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3965e4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_path_head = []\n",
    "last_labels_array = np.array([])\n",
    "current_array = np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b53ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import io\n",
    "import os\n",
    "\n",
    "with torch.no_grad():\n",
    "    # for data in loader:\n",
    "    for images, labels, paths in loader:\n",
    "        #print('data = ', data)\n",
    "        print('labels = ', labels)\n",
    "        # print('images = ', images)\n",
    "        # print('paths = ', paths)\n",
    "\n",
    "        labels_array = labels.cpu().detach().numpy()\n",
    "        # print('labels_array = ', labels_array)\n",
    "        if last_labels_array.size == 0:\n",
    "            last_labels_array = labels_array\n",
    "\n",
    "        # Split the path in\n",
    "        # head and tail pair\n",
    "        path = paths[0]\n",
    "        head_tail = os.path.split(path)\n",
    "        # print head and tail\n",
    "        # of the specified path\n",
    "        # print(\"Head of '% s:'\" % path, head_tail[0])\n",
    "        # print(\"Tail of '% s:'\" % path, head_tail[1], \"\\n\")\n",
    "        if not current_path_head:\n",
    "            current_path_head = head_tail[0]\n",
    "        else:\n",
    "            if current_path_head != head_tail[0]:\n",
    "                outputs_matrix = np.asmatrix(current_array)\n",
    "                # print('outputs_matrix = ', outputs_matrix)\n",
    "                print('outputs_matrix.shape = ', outputs_matrix.shape)\n",
    "                # scipy.io.savemat()\n",
    "                # io.savemat([os.path.basename(current_path_head)+'.mat'], {'feature': outputs_matrix, 'label': labels_array})\n",
    "                print('last_labels_array = ', last_labels_array)\n",
    "                io.savemat(current_path_head+'.mat', {'feature': outputs_matrix, 'label': last_labels_array})\n",
    "                print('Save mat file to:', current_path_head+'.mat')\n",
    "                current_path_head = head_tail[0]\n",
    "                current_array = np.array([])\n",
    "        last_labels_array = labels_array\n",
    "\n",
    "        images = images.to(device)\n",
    "        outputs = features32(model,images)\n",
    "        # print('outputs = ', outputs)\n",
    "        outputs_array = outputs.cpu().detach().numpy()\n",
    "\n",
    "        # np.reshape(outputs_array, (1, outputs_array.size))\n",
    "        # print('outputs_array = ', outputs_array)\n",
    "        # print('outputs_array.size = ', outputs_array.size)\n",
    "        if current_array.size == 0:\n",
    "            current_array = outputs_array\n",
    "            # print('current_array = ', current_array)\n",
    "            # print('current_array.shape = ', current_array.shape)\n",
    "        else:\n",
    "            # current_array = np.append(current_array, outputs_array, axis=0)\n",
    "            current_array = np.vstack([current_array, outputs_array])\n",
    "            # print('current_array = ', current_array)\n",
    "            # print('current_array.shape = ', current_array.shape)\n",
    "\n",
    "    # Save for the last folder:\n",
    "    outputs_matrix = np.asmatrix(current_array)\n",
    "    # print('outputs_matrix = ', outputs_matrix)\n",
    "    print('outputs_matrix.shape = ', outputs_matrix.shape)\n",
    "    # scipy.io.savemat()\n",
    "    # io.savemat([os.path.basename(current_path_head)+'.mat'], {'feature': outputs_matrix, 'label': labels_array})\n",
    "    print('labels_array = ', labels_array)\n",
    "    io.savemat(current_path_head+'.mat', {'feature': outputs_matrix, 'label': labels_array})\n",
    "    print('Save mat file to:', current_path_head+'.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b50170",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
